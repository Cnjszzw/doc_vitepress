import{_ as o,c as t,o as e,ae as r}from"./chunks/framework.Dh1jimFm.js";const h=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"companyDoc/实时音视频技术学习文档.md","filePath":"companyDoc/实时音视频技术学习文档.md"}'),n={name:"companyDoc/实时音视频技术学习文档.md"};function s(p,a,c,d,i,_){return e(),t("div",null,a[0]||(a[0]=[r('<h3 id="视频" tabindex="-1">视频 <a class="header-anchor" href="#视频" aria-label="Permalink to &quot;视频&quot;">​</a></h3><p>本质上是由图片，通常比如1秒24张，30张，连续播放就生产了视频。</p><p>其中这个张，更专业的说法叫做**<code>帧</code><strong>,一秒有多少帧，叫</strong><code>帧率</code>**。</p><h3 id="色彩" tabindex="-1">色彩 <a class="header-anchor" href="#色彩" aria-label="Permalink to &quot;色彩&quot;">​</a></h3><p>常用的有**<code>RGB</code><strong>和</strong><code>YUV</code>**，RGB代表红黄蓝，三种颜色按比例混合，可以调出任意颜色。YUV，Y是亮度，U是蓝色和亮度的差值，V是红色和亮度的差值，按照比例混合也可以混合出任意颜色。可以理解为两种颜色的编码方式。</p><h3 id="音频" tabindex="-1">音频 <a class="header-anchor" href="#音频" aria-label="Permalink to &quot;音频&quot;">​</a></h3><p>音频本质是波，一般用PCM，脉冲编码调制来把声音数字化。</p><p>PCM的步骤，主要有以下：</p><p>模拟信号 - &gt; 采样 - &gt; 量化 -&gt; 编码 - &gt;数字信号</p><p>**采样率：**这个主要是采样的频率</p><p><strong>采样位数</strong>：这个主要是模拟振幅的最大最小值，如果是16位，那就是最小值为-32768 , 最大值为32767</p><p><strong>编码</strong>：就是把幅度值转换为0和1存储</p><p><strong>声道数</strong>：就是能支持不同声音的音响个数</p><p><strong>码率</strong>：码率，是指一个数据流中每秒钟能通过的信息量，单位bps（bit per second）。</p><h3 id="编码-压缩" tabindex="-1">编码（压缩） <a class="header-anchor" href="#编码-压缩" aria-label="Permalink to &quot;编码（压缩）&quot;">​</a></h3><p>如果不进行压缩，存储所有的信息，那么一分钟的视频可能有上百GB，因此普遍需要算法来进行压缩。视频的话一般有h264，音频一般有AAC等</p><h3 id="解码" tabindex="-1">解码 <a class="header-anchor" href="#解码" aria-label="Permalink to &quot;解码&quot;">​</a></h3><p><strong>软解码</strong>：利用CPU解码计算画面，兼容性好，但是速度慢，容易发热</p><p><strong>硬解码</strong>：用专门的解码芯片来实现，性能好，但是每个厂家实现方式不同，兼容性差</p>',19)]))}const g=o(n,[["render",s]]);export{h as __pageData,g as default};
